---
id: "0004"
title: AI Agent Full Implementation
stage: green
date: 2026-02-17
surface: agent
model: claude-sonnet-4-6
feature: 003-ai-agent-interface
branch: 003-ai-agent-interface
user: Jannat Osmani
command: /sp.implement
labels: ["implement","ai-agent","mcp","openai-agents-sdk","fastapi","chat","frontend","nextjs"]
links:
  spec: specs/003-ai-agent-interface/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - backend/app/models/conversation.py
  - backend/app/models/message.py
  - backend/app/mcp_server/__init__.py
  - backend/app/mcp_server/server.py
  - backend/app/agent/__init__.py
  - backend/app/agent/prompts.py
  - backend/app/agent/runner.py
  - backend/app/routers/chat.py
  - backend/app/config.py
  - backend/app/main.py
  - frontend/lib/api.ts
  - frontend/components/chat/ChatMessage.tsx
  - frontend/components/chat/ChatInput.tsx
  - frontend/components/chat/ChatPanel.tsx
  - frontend/app/dashboard/page.tsx
  - specs/003-ai-agent-interface/tasks.md
tests:
  - n/a (manual acceptance testing per quickstart.md)
---

## Prompt

/sp.implement

## Response snapshot

Implemented all 23 tasks (T-300â€“T-322) across 4 phases:

**Phase 1 â€” Database Infrastructure** âœ…
- conversation.py: Conversation SQLModel (id UUID, user_id indexed, created_at)
- message.py: Message SQLModel (id UUID, conversation_id FK, role VARCHAR20, content TEXT, composite index ix_message_conv_created)
- mcp_server/__init__.py + server.py scaffold with FastMCP("task-manager") and stdio entrypoint
- agent/__init__.py package init
- main.py updated to explicitly import new models for init_db()

**Phase 2 â€” MCP Tool Implementation** âœ…
- Installed openai-agents==0.9.1 and mcp==1.26.0
- All 5 tools implemented in mcp_server/server.py using raw SQL via AsyncSession:
  - list_tasks (read): filters by user_id, optional status, returns {status, tasks, count}
  - add_task (write): inserts new row, returns {status: "created", task_id, title, description}
  - update_task (write): verifies ownership, updates title/description
  - delete_task (write): scoped DELETE, returns rowcount check
  - complete_task (write): sets status="completed", verifies ownership

**Phase 3 â€” Agent Logic** âœ…
- config.py: Added OPENAI_API_KEY and OPENAI_MODEL (default: gpt-4o)
- agent/prompts.py: SYSTEM_PROMPT with tool use instructions, context resolution rules, brevity rules
- agent/runner.py: get_mcp_server() singleton with sys.executable + MCPServerStdio; run_agent() creates fresh Agent per request; shutdown_mcp_server() for lifespan
- routers/chat.py: ChatRequest/ChatResponse/MessageRead/HistoryResponse schemas; get_or_create_conversation, load_messages (capped 100), save_message helpers; POST /api/chat (5-step stateless flow); GET /api/chat/history
- main.py: chat router registered; lifespan calls shutdown_mcp_server() on exit

**Phase 4 â€” Frontend Interface** âœ…
- lib/api.ts: fetchChatHistory() and sendChatMessage() added
- ChatMessage.tsx: user (right/indigo) + assistant (left/gray) bubbles with lucide icons
- ChatInput.tsx: auto-resize textarea; Enter sends, Shift+Enter newlines; spinner when disabled
- ChatPanel.tsx: loads history on mount; optimistic user message append; typing indicator (3-dot bounce); calls onTaskMutated() after each successful response
- dashboard/page.tsx: flex-col xl:flex-row layout with ChatPanel in w-96 right column

Key discoveries during implementation:
- MCPServerStdio import path is agents.mcp (not agents directly)
- MCPServerStdioParams is a plain dict type alias
- Runner.run is async; result.final_output is the response text
- Used sys.executable instead of "python" to guarantee same venv for subprocess
- Frontend build: clean (0 errors, 0 warnings)

## Outcome

- âœ… Impact: Complete AI agent chat interface â€” backend (FastAPI + OpenAI Agents SDK + MCP) and frontend (ChatPanel) fully implemented and build-verified
- ğŸ§ª Tests: Frontend build passes clean; backend import test passes; manual acceptance checklist in quickstart.md
- ğŸ“ Files: 15 files created/modified across backend and frontend
- ğŸ” Next prompts: Start both servers and run acceptance checklist from quickstart.md
- ğŸ§  Reflection: Using sys.executable for MCPServerStdio ensures the subprocess uses the same virtual environment. Runner.run is async and result.final_output holds the natural-language reply. Frontend build is clean with zero TypeScript errors.

## Evaluation notes (flywheel)

- Failure modes observed: none (all builds pass)
- Graders run and results (PASS/FAIL): frontend build âœ…, backend import test âœ…
- Prompt variant (if applicable): n/a
- Next experiment (smallest change to try): run acceptance test from quickstart.md to verify end-to-end flow with real OpenAI API
